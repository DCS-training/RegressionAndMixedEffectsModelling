---
title: "2025LMMcourse Session 3 Practical"
author: "Fang Yang"
date: "2025-05-09"
output: bookdown::pdf_document2
toc: false
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE, results='hide')
```

```{r install packages, include=FALSE}
library("tidyverse")
library("lme4")
library("effects")
library("sjPlot") # for presenting model results (nice tables)
library("interactions")
library("webshot") # for converting tab_model shot from html to png and include it in the .pdf file of the report
library("kableExtra") # for creating descriptive statistics tables
library("patchwork") # for arrange plots 

library("broom.mixed") #"broom" for mixed models, used to turn messy R output into nicer table and plots

knitr::opts_chunk$set(warning = FALSE, message = FALSE) 
```

# Part I. Outstanding questions from last time

## What is ICC

First of all what is the residual of the random effects (sigma squared)? 
It is also called Residual Variance, which represents the within group variances.

When dealing with hierarchical modelling, the variances come from both within group (e.g., between different tests of a particular participant) and between group (e.g., between different participants).

To help us visualise this, recall our plot from last time

```{r load data}
vocabdata <- read_csv("vocabtrainingdata.csv")

vocabdata$proficiency <- as.factor(vocabdata$proficiency)
```


```{r}

#rerun the model
mMixed_reduced <- lmerTest::lmer(vocab_test_score ~ week * proficiency + 
                                (1 + week | participant),
                              data = vocabdata,
                              control=lmerControl(optimizer="bobyqa",
                                 optCtrl=list(maxfun=2e5)))
# plot
augment(mMixed_reduced) |> 
  ggplot(aes(x = week, y = .fitted, color = participant)) + 
  geom_line() + 
  geom_point(aes(y=vocab_test_score), alpha=.5)+ 
  geom_abline(intercept = fixef(mMixed_reduced)[1], 
              slope = fixef(mMixed_reduced)[2], lwd = 1.5, colour ="orange") +
  geom_abline(intercept = fixef(mMixed_reduced)[1] + fixef(mMixed_reduced)[3], 
              slope= fixef(mMixed_reduced)[2] + fixef(mMixed_reduced)[4],lwd = 1.5, colour ="darkblue")+
  theme(legend.position='none')+
  labs(x="Number of Weeks Spent on the Course", 
       y = "Predicted Vocabulary Test Score",
       title = "Predicted Effects of the Online Course on Vocabulary Test Score")
#+ facet_wrap(~proficiency)
```

So the key is to understand between-group variance and within-group variance (i.e., residuals)

ICC stands for "IntraClass Correlation Coefficient".

It represents how much variation in a variable is attributable to the grouping factor.

ICC = Variance between the groups / Total variance in the variable
= Between group variances / (Between Group Variances + Within Group Variances)

The ICC is calculated by dividing the random effect variance, sigma squaredi, by the total variance, i.e. the sum of the random effect variance (i.e., between-group variances) and the residual variance (i.e., within group variances), sigma squared or epsilon.

The higher the ICC is, the more justified for fitting a hierarchical model. It ranges from 0 to 1 (with no cutoffs).

Let's put this all in context. Recall our model results from last time. 

```{r echo = T}
# recall our model from last time

# the intercept-only model
mMixed_simplest.model <- lmerTest::lmer(vocab_test_score ~ week * proficiency + 
                                   (1 | participant),
                              data = vocabdata,
                              control=lmerControl(optimizer="bobyqa",
                                 optCtrl=list(maxfun=2e5)))
summary(mMixed_simplest.model)
tab_model(mMixed_simplest.model)

# Residual of the random effects (residual variance): sigma squared = 35.45 
# this is the WITHIN-group (or residual) variance 

# Random intercept variance: Tau00_participant = 25.47 
# this is the BETWEEN-group variance for the intercept 

# ICC = Between/(Between + Within) = 25.47/(25.47+35.45) = 0.42

```


```{r echo=T}

mMixed_reduced <- lmerTest::lmer(vocab_test_score ~ week * proficiency + 
                                (1 + week | participant),
                              data = vocabdata,
                              control=lmerControl(optimizer="bobyqa",
                                 optCtrl=list(maxfun=2e5)))
summary(mMixed_reduced)

tab_model(mMixed_reduced)

# Residual of the random effects (residual variance): sigma squared = 29.51. 
# This is the WITHIN-group (or residual) variance 

# Between-group random intercept variance: Tau00_participant = 10.09. 
# This is the BETWEEN-group variance for the intercept.

# Between-group random slope variance: Tau11 = 0.69. This represents how much 
# groups or subjects differ from each other in their slopes, i.e., in their 
# responses to a particular fixed effect (e.g., week).

# Random slope-intercept correlation : Rho01 participant = 0.11. 

# ICC = between-group variance/total variance 
#     = (10.09 * 0.69)/(10.09 * 0.69 + 29.51) 
#     = 0.19

``` 

Why on earth does the tab_model results report ICC = 0.52 then?

Because icc() calculates an adjusted and an unadjusted ICC, which both take 
all sources of uncertainty (i.e. of all random effects) into account. While 
the adjusted ICC only relates to the random effects, the unadjusted ICC also 
takes the fixed effects variances into account, more precisely, the fixed 
effects variance is added to the denominator of the formula to calculate the
ICC (see Nakagawa et al. 2017). Typically, the adjusted ICC is of interest when
the analysis of random effects is of interest. source: https://easystats.github.io/performance/reference/icc.html

```{r echo=T}
# we can use the icc() function from the "performance" package to extract 
# both ICC values directly

library("performance")
icc(mMixed_reduced) # unadjusted ICC = 0.19, matching our manual calculation.
```


# Part II. Exercise - Continue exploring the vocab_learning data

Can you fit a model with a different structure of random effects and interpret 
the results? 

Hint: consider including some or all of the following:
	 - random intercept?  
	 - random slope of one predictor?
	 - random slopes of both predictors?
	 - random slope of the interaction between the two predictors?
 
## Example 1 

Model with random intercept and random slope of "proficiency"

```{r}
m4 <- lmer(vocab_test_score ~ week * proficiency + 
             (1 + proficiency| participant), data = vocabdata)
summary(m4) # failed to converge
```


```{r}
m4a <- lmer(vocab_test_score ~ week * proficiency + 
             (1 + proficiency| participant), data = vocabdata)
summary(m4) # failed to converge
```

Tips: Deal with boundry fit issue.

Note the last line in the output; "boundary (singular) fit: see help('isSingular')", nearly suggesting overfitting. Basically, your model is over thinking - there is not as much variation in the data as the model tries to construct. 

Solutions:
1. Remove the most complex part of the random effects structure (i.e. random slopes)
2. Maybe acceptable to remove a specific random effect term when its variance estimates are very low

## Example 2 

Model with intercept and slopes of both "week" and "proficiency"

```{r}
m5 <- lmer(vocab_test_score ~ week * proficiency + 
             (1 + week + proficiency| participant), 
           REML=FALSE, 
           data = vocabdata)
summary(m5)
```

Tips: Deal with convergence issue.

Note the last line in the output; Model failed to converge with max|grad| = 0.00665298 (tol = 0.002, component 1).The optimiser we are using canâ€™t find a suitable estimation for the maximum likelihood. 

One solution is to adjust stopping (convergence) tolerances for the nonlinear optimizer, using the optCtrl() argument to lmerControl. 

Now include optimizer control in the model and refit

```{r}
m6 <- lmer(vocab_test_score ~ week * proficiency + 
             (1 + week + proficiency| participant), 
           data = vocabdata, 
           REML=FALSE, 
           lmerControl(optimizer = "bobyqa"))

summary(m6) # still over fitting


# next we check the variance and remove those random coefficients that are close
# to zero. we can see variances between weeks are small (var = 0.65). we can 
# then remove it and include only random slopes of proficiency

```

It seems our best choice is (1 + week| participant) for this dataset.

# Part III. A NEW DATASET

A tech company are exploring whether the daily time their customers spend on Instagram is dependent of customers' occupation: undergraduates, full-time employees, vs. the retired. They randomly sampled 15-20 customers from each population and collected other information (e.g., age, being a user of TikTok or not).They tracked the participants for 6 weeks.

```{r}
# load the dataset into R
data_IGtime <- read.csv("IGtime TikTok data.csv")

# check variables 
summary(data_IGtime)
str(data_IGtime)
# set categorical variable as factor

data_IGtime$Occupation<-as.factor(data_IGtime$Occupation)
data_IGtime$TikTok.user<-as.factor(data_IGtime$TikTok.user)

summary(data_IGtime)
str(data_IGtime)
```


```{r}
# visualise data 
with(data_IGtime, plot(time_on_Instagram_daily ~ Occupation))


# plot data
ggplot(data_IGtime, aes(x=week, y=time_on_Instagram_daily, colour = Occupation)) +
   geom_point(size = 2.5)+ 
  ggtitle(label = "Average time spent on Instagram daily by different groups")+
  labs(y = "Time(mins)", 
       x= "week" )+ 
  theme(plot.title = element_text(hjust = 0.5, size=18,face = "bold"),
        axis.text.x = element_text(size=14,face = "bold"),
        axis.title.x = element_text(size=16,face = "bold"),
        axis.title.y = element_text(size=16,face = "bold"),
        legend.title = element_text(size=16,face = "bold"),
        legend.text = element_text(size=12,face = "bold")
  )

### plot data with mean

##calculate mean and sd
ds <- do.call(rbind, lapply(split(data_IGtime, data_IGtime$Occupation), 
                            function(d) {
  data.frame(mean = mean(d$time_on_Instagram_daily), sd = sd(d$time_on_Instagram_daily), Occupation = d$Occupation)
}))

# plot data with mean and error bar
ggplot(data_IGtime, aes(colour=week, y=time_on_Instagram_daily, x = Occupation, shape = Occupation)) +
   geom_point(size = 3)+ 
   geom_point(data = ds, aes(x=Occupation, y=mean), col="black", size=5) +
    ggtitle(label = "Average time spent on Instagram daily by different groups")+
    geom_errorbar(
     data = ds,
     aes(Occupation, mean, ymin = mean - sd, ymax = mean + sd),
     colour = 'black', size=0.6, width = 0.2)+
  ggtitle(label = "Average time spent on Instagram daily\nby different groups")+
  labs(y = "Time(mins)", 
       x= "week" )+ 
  theme(plot.title = element_text(hjust = 0.5, size=18,face = "bold"),
        axis.text.x = element_text(size=14,face = "bold"),
        axis.title.x = element_text(size=16,face = "bold"),
        axis.title.y = element_text(size=16,face = "bold"),
        legend.title = element_text(size=16,face = "bold"),
        legend.text = element_text(size=12,face = "bold")
  )

```

Next you can try to fit some models.

Start with a simple regression without random effects?

```{r}
# a starting point

my_model <- lm (time_on_Instagram_daily ~ Occupation, data_IGtime) # note this is a simple regression. How would you make other useful information from the dataset and fit mixed-effect models?
```

How about a mixed-effect model? What factors can be treated as random effects? 

```{r}
#an Example

my_model2 <- lmerTest::lmer (time_on_Instagram_daily ~ Occupation + (1| Participant), data_IGtime)


```

Anything else you may want to include as fixed effects? Do you have theoretical/practical justification for this? 

```{r}

# other things you can consider include

my_model3 <- lmerTest::lmer (time_on_Instagram_daily ~ Occupation * TikTok.user
                             + (1| Participant), 
                             data = data_IGtime)
summary(my_model3 )
tab_model(my_model3 )


my_model3B <- lmerTest::lmer (time_on_Instagram_daily ~ Occupation * TikTok.user
                              + (1 + Occupation + TikTok.user | Participant),
                              data = data_IGtime)

tab_model(my_model3B)
```

# Part IV. Self-reflection & Discussion

In what ways can linear mixed-effects models help you address the research 
questions of your own research  ?
